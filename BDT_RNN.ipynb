{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1ddfd3c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sanhi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import LSTM, Dense, Dropout, Masking, Embedding\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe6ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Labeled_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b49ed3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>astroworld</td>\n",
       "      <td>2020-07-25 12:27:21</td>\n",
       "      <td>smelled the scent hand sanitizers today someon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>2020-07-25 12:27:17</td>\n",
       "      <td>Hey and wouldn't have made more sense have the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pewee Valley, KY</td>\n",
       "      <td>2020-07-25 12:27:14</td>\n",
       "      <td>Trump never once claimed COVID19 was hoax. all...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stuck in the Middle</td>\n",
       "      <td>2020-07-25 12:27:10</td>\n",
       "      <td>The one gift COVID19 has give appreciation for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>2020-07-25 12:27:08</td>\n",
       "      <td>July Media Bulletin Novel CoronaVirusUpdates C...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_location                 date  \\\n",
       "0            astroworld  2020-07-25 12:27:21   \n",
       "1          New York, NY  2020-07-25 12:27:17   \n",
       "2      Pewee Valley, KY  2020-07-25 12:27:14   \n",
       "3  Stuck in the Middle   2020-07-25 12:27:10   \n",
       "4     Jammu and Kashmir  2020-07-25 12:27:08   \n",
       "\n",
       "                                        cleaned_text  sentiment  \n",
       "0  smelled the scent hand sanitizers today someon...          0  \n",
       "1  Hey and wouldn't have made more sense have the...          2  \n",
       "2  Trump never once claimed COVID19 was hoax. all...          1  \n",
       "3  The one gift COVID19 has give appreciation for...          1  \n",
       "4  July Media Bulletin Novel CoronaVirusUpdates C...          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb8433ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_location</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179093</th>\n",
       "      <td>Norwalk, CT</td>\n",
       "      <td>2020-08-29 19:44:48</td>\n",
       "      <td>what are those library cats doing now covid19 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179094</th>\n",
       "      <td>Utrecht</td>\n",
       "      <td>2020-08-29 19:44:46</td>\n",
       "      <td>\"symptom screening fails identify most covid19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179095</th>\n",
       "      <td>Lansing, MI</td>\n",
       "      <td>2020-08-29 19:44:42</td>\n",
       "      <td>covid19 update new cases today the tri-county ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179096</th>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>2020-08-29 19:44:40</td>\n",
       "      <td>were really bummed couldnâ€™t cop one these time...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179097</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-29 19:44:35</td>\n",
       "      <td>just not the lives covid19 sufferers coronavir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179098</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-29 19:44:34</td>\n",
       "      <td>report covid19 outbreaks k-12 schools here clo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179099</th>\n",
       "      <td>la playa, el mar .. mi corazÃ³n</td>\n",
       "      <td>2020-08-29 19:44:34</td>\n",
       "      <td>have nothing but for the these days not only d...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179100</th>\n",
       "      <td>Newton, NJ</td>\n",
       "      <td>2020-08-29 19:44:27</td>\n",
       "      <td>wallkill school nurse adds covid-19 monitoring...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179101</th>\n",
       "      <td>Newton, NJ</td>\n",
       "      <td>2020-08-29 19:44:27</td>\n",
       "      <td>wallkill school nurse adds covid-19 monitoring...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179102</th>\n",
       "      <td>T.O.</td>\n",
       "      <td>2020-08-29 19:44:23</td>\n",
       "      <td>have reached 25mil cases covid19 worldwide oof</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179103</th>\n",
       "      <td>Ilorin, Nigeria</td>\n",
       "      <td>2020-08-29 19:44:21</td>\n",
       "      <td>thanks for nominating for the wearamask challe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179104</th>\n",
       "      <td>Ontario</td>\n",
       "      <td>2020-08-29 19:44:16</td>\n",
       "      <td>2020 the year insanity lol covid19</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179105</th>\n",
       "      <td>ðŸ‡¨ðŸ‡¦ Canada</td>\n",
       "      <td>2020-08-29 19:44:15</td>\n",
       "      <td>powerful painting juan lucena it's tribute the...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179106</th>\n",
       "      <td>New York City</td>\n",
       "      <td>2020-08-29 19:44:14</td>\n",
       "      <td>more than 1200 students test positive for covi...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179107</th>\n",
       "      <td>Aliwal North, South Africa</td>\n",
       "      <td>2020-08-29 19:44:08</td>\n",
       "      <td>stop when see stop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         user_location                 date  \\\n",
       "179093                     Norwalk, CT  2020-08-29 19:44:48   \n",
       "179094                         Utrecht  2020-08-29 19:44:46   \n",
       "179095                     Lansing, MI  2020-08-29 19:44:42   \n",
       "179096                 Los Angeles, CA  2020-08-29 19:44:40   \n",
       "179097                             NaN  2020-08-29 19:44:35   \n",
       "179098                             NaN  2020-08-29 19:44:34   \n",
       "179099  la playa, el mar .. mi corazÃ³n  2020-08-29 19:44:34   \n",
       "179100                      Newton, NJ  2020-08-29 19:44:27   \n",
       "179101                      Newton, NJ  2020-08-29 19:44:27   \n",
       "179102                            T.O.  2020-08-29 19:44:23   \n",
       "179103                 Ilorin, Nigeria  2020-08-29 19:44:21   \n",
       "179104                         Ontario  2020-08-29 19:44:16   \n",
       "179105                       ðŸ‡¨ðŸ‡¦ Canada  2020-08-29 19:44:15   \n",
       "179106                   New York City  2020-08-29 19:44:14   \n",
       "179107      Aliwal North, South Africa  2020-08-29 19:44:08   \n",
       "\n",
       "                                             cleaned_text  sentiment  \n",
       "179093  what are those library cats doing now covid19 ...          1  \n",
       "179094  \"symptom screening fails identify most covid19...          1  \n",
       "179095  covid19 update new cases today the tri-county ...          2  \n",
       "179096  were really bummed couldnâ€™t cop one these time...          2  \n",
       "179097  just not the lives covid19 sufferers coronavir...          1  \n",
       "179098  report covid19 outbreaks k-12 schools here clo...          1  \n",
       "179099  have nothing but for the these days not only d...          1  \n",
       "179100  wallkill school nurse adds covid-19 monitoring...          1  \n",
       "179101  wallkill school nurse adds covid-19 monitoring...          1  \n",
       "179102     have reached 25mil cases covid19 worldwide oof          1  \n",
       "179103  thanks for nominating for the wearamask challe...          2  \n",
       "179104                 2020 the year insanity lol covid19          2  \n",
       "179105  powerful painting juan lucena it's tribute the...          2  \n",
       "179106  more than 1200 students test positive for covi...          2  \n",
       "179107                                 stop when see stop          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned_text'] = df['cleaned_text'].astype(str)  # Convert to string type\n",
    "df['cleaned_text'] = df['cleaned_text'].apply(lambda x: x.lower())  # Convert to lowercase\n",
    "most_common_word = df['cleaned_text'].mode().iloc[0]\n",
    "df['cleaned_text'].fillna(most_common_word, inplace=True)\n",
    "df['cleaned_text'] = df['cleaned_text'].str.replace('[?!:;..,]', '', regex=True)\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf0e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels=tf.keras.utils.to_categorical(y, 5,dtype =\"int32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3801a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tokenizer = Tokenizer()\n",
    "#tokenizer.fit_on_texts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76eefda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequences = tokenizer.texts_to_sequences(df)\n",
    "#text = pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ba8b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_words = len(tokenizer.word_index) + 1\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, labels, train_size=0.75, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00c4ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_train.shape)\n",
    "#print(X_test.shape)\n",
    "#print(y_train.shape)\n",
    "#print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63b8db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import random\n",
    "#import os\n",
    "####*IMPORANT*: Have to do this line *before* importing tensorflow\n",
    "#os.environ['PYTHONHASHSEED']=str(1)\n",
    "\n",
    "#def reset_random_seeds():\n",
    "#   os.environ['PYTHONHASHSEED']=str(1)\n",
    " #  tf.random.set_seed(1)\n",
    "  # np.random.seed(1)\n",
    "   #random.seed(1)\n",
    "\n",
    "#make some random data\n",
    "#reset_random_seeds()\n",
    "\n",
    "#reset_random_seeds() \n",
    "#model1 = Sequential()\n",
    "\n",
    "#model1.add(layers.Embedding(num_words, 1000))\n",
    "#model1.add(layers.SimpleRNN(128,dropout=0.9))\n",
    "#model1.add(Dropout(0.09))\n",
    "#model1.add(Dropout(0.05))\n",
    "#model1.add(layers.Dense(5,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b67d02b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.cleaned_text\n",
    "Y = df.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4929fa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "Y = le.fit_transform(Y)\n",
    "Y = Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a07bdc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [2],\n",
       "       [1],\n",
       "       ...,\n",
       "       [2],\n",
       "       [2],\n",
       "       [1]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6937d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into training and test data.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "413400a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95943     official covid19 update thailand sunday ðŸ”¸3351 ...\n",
       "127266    badayetechtw20kit are live \"tukyusa bulamu\" ha...\n",
       "29454     prime minister shri narendra modi will launch ...\n",
       "106824    ewik particularly nasty bot that chooses keep ...\n",
       "140626    jeez are they still bleating with this irrelev...\n",
       "                                ...                        \n",
       "93997     india plans fell ecologically sensitive forest...\n",
       "80248     please commit first trimester schools remote l...\n",
       "49865     breaking cured except for the mold mold his lu...\n",
       "54015     mumbai's latest covid19 status glance case sum...\n",
       "157952        watching this has been worse for than covid19\n",
       "Name: cleaned_text, Length: 143286, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ef7deff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence\n",
    "max_words = 1000\n",
    "max_len = 250\n",
    "tok = Tokenizer(num_words=max_words)\n",
    "tok.fit_on_texts(X_train)\n",
    "sequences = tok.texts_to_sequences(X_train)\n",
    "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37abbf4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[725, 2, 75, 538, 22, 363, 445, 618, 10, 170, 486]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f5b32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "7\n",
      "5\n",
      "2\n",
      "9\n",
      "15\n",
      "10\n",
      "3\n",
      "6\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(sequences[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ebd54705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(sequences_matrix[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "407cb7db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0, 725,   2,  75, 538,  22, 363, 445, 618,\n",
       "        10, 170, 486])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences_matrix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bce4e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b52ddea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hey and wouldn't have made more sense have the players pay their respects the\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "065af84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import SimpleRNN, Activation, Dense, Dropout, Input, Embedding, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "def RNNmodel():\n",
    "    inputs = Input(name='inputs',shape=[max_len])\n",
    "    layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
    "    layer = LSTM(32)(layer)\n",
    "    layer = Dense(256,name='FC1',activation='relu')(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = Dropout(0.5)(layer)\n",
    "    layer = Dense(1,name='out_layer')(layer)\n",
    "    layer = Activation('sigmoid')(layer)\n",
    "    model = Model(inputs=inputs,outputs=layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8924a9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sanhi\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " inputs (InputLayer)         [(None, 250)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 250, 50)           50000     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 32)                10624     \n",
      "                                                                 \n",
      " FC1 (Dense)                 (None, 256)               8448      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " out_layer (Dense)           (None, 1)                 257       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 69329 (270.82 KB)\n",
      "Trainable params: 69329 (270.82 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\sanhi\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RNNmodel()\n",
    "model.summary()\n",
    "model.compile(loss='binary_crossentropy',optimizer='rmsprop',metrics=['accuracy',tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b674caef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\sanhi\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\sanhi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "896/896 [==============================] - 191s 208ms/step - loss: -295.4244 - accuracy: 0.4194 - precision: 0.8345 - val_loss: -823.8884 - val_accuracy: 0.4148 - val_precision: 0.8331\n",
      "Epoch 2/10\n",
      "896/896 [==============================] - 192s 214ms/step - loss: -1792.3298 - accuracy: 0.4195 - precision: 0.8344 - val_loss: -3028.9290 - val_accuracy: 0.4148 - val_precision: 0.8331\n",
      "Epoch 3/10\n",
      "896/896 [==============================] - 202s 226ms/step - loss: -4679.3950 - accuracy: 0.4195 - precision: 0.8344 - val_loss: -6617.1187 - val_accuracy: 0.4148 - val_precision: 0.8331\n",
      "Epoch 4/10\n",
      "896/896 [==============================] - 201s 225ms/step - loss: -8892.1064 - accuracy: 0.4195 - precision: 0.8344 - val_loss: -11599.4082 - val_accuracy: 0.4148 - val_precision: 0.8331\n",
      "Epoch 5/10\n",
      "896/896 [==============================] - 201s 224ms/step - loss: -15194.2451 - accuracy: 0.4237 - precision: 0.8383 - val_loss: -21265.3516 - val_accuracy: 0.4402 - val_precision: 0.8556\n",
      "Epoch 6/10\n",
      "896/896 [==============================] - 196s 219ms/step - loss: -26620.0332 - accuracy: 0.4611 - precision: 0.8719 - val_loss: -30320.6289 - val_accuracy: 0.4521 - val_precision: 0.8651\n",
      "Epoch 7/10\n",
      "896/896 [==============================] - 192s 215ms/step - loss: -38242.1797 - accuracy: 0.4669 - precision: 0.8768 - val_loss: -44853.1680 - val_accuracy: 0.4707 - val_precision: 0.8829\n",
      "Epoch 8/10\n",
      "896/896 [==============================] - 202s 225ms/step - loss: -50863.9609 - accuracy: 0.4663 - precision: 0.8779 - val_loss: -59019.8555 - val_accuracy: 0.4653 - val_precision: 0.8779\n",
      "Epoch 9/10\n",
      "896/896 [==============================] - 193s 215ms/step - loss: -66635.4844 - accuracy: 0.4727 - precision: 0.8823 - val_loss: -75276.7031 - val_accuracy: 0.4792 - val_precision: 0.8919\n",
      "Epoch 10/10\n",
      "896/896 [==============================] - 175s 196ms/step - loss: -83623.8438 - accuracy: 0.4726 - precision: 0.8822 - val_loss: -93153.5938 - val_accuracy: 0.4877 - val_precision: 0.9011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x209a6aaf190>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4f754ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tok.texts_to_sequences(X_test)\n",
    "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd90da6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1120/1120 [==============================] - 39s 35ms/step - loss: -94449.8359 - accuracy: 0.4890 - precision: 0.9057\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(test_sequences_matrix,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d52655eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set\n",
      "  Loss: -94449.836\n",
      "  Accuracy: 0.489\n"
     ]
    }
   ],
   "source": [
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f6e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98863b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68b4a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
